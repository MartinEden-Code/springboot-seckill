
spring.application.name=seckill
server.port=8083
#thymeleaf
spring.thymeleaf.prefix=classpath:/templates/
spring.thymeleaf.suffix=.html
spring.thymeleaf.cache=false
spring.thymeleaf.content-type=text/html
spring.thymeleaf.enabled=true
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.mode=HTML5
# mybatis
mybatis.type-aliases-package=com.jesper.seckill.mapper
mybatis.configuration.map-underscore-to-camel-case=true
mybatis.configuration.default-fetch-size=100
mybatis.configuration.default-statement-timeout=3000
mybatis.mapperLocations = classpath:com/jesper/seckill/mapper/*.xml
# druid
spring.datasource.url=jdbc:mysql://localhost:3306/seckill?useUnicode=true&characterEncoding=utf-8&allowMultiQueries=true&useSSL=false
spring.datasource.username=root
spring.datasource.password=yuantu123
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.filters=stat
spring.datasource.maxActive=1000
spring.datasource.initialSize=100
spring.datasource.maxWait=60000
spring.datasource.minIdle=500
spring.datasource.timeBetweenEvictionRunsMillis=60000
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=select 'x'
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
spring.datasource.poolPreparedStatements=true
spring.datasource.maxOpenPreparedStatements=20
#redis
redis.host=127.0.0.1
redis.port=6379
redis.timeout=10
redis.poolMaxTotal=1000
redis.poolMaxIdle=500
redis.poolMaxWait=500
redis.password=yuantu123

spring.redis.password=yuantu123

spring.redis.jedis.pool.max-active=100
spring.redis.jedis.pool.max-idle=100
spring.redis.jedis.pool.min-idle=10
spring.redis.jedis.pool.max-wait=50000ms

#static
spring.resources.add-mappings=true
spring.resources.cache-period= 3600
spring.resources.chain.cache=true 
spring.resources.chain.enabled=true
spring.resources.chain.gzipped=true
spring.resources.chain.html-application-cache=true
spring.resources.static-locations=classpath:/static/


#rabbitmq
spring.rabbitmq.host=127.0.0.1
spring.rabbitmq.port=5672
spring.rabbitmq.username=guest
spring.rabbitmq.password=guest
spring.rabbitmq.virtual-host=/
#最小的消费者数量
spring.rabbitmq.listener.simple.concurrency= 10
#最大的消费者数量
spring.rabbitmq.listener.simple.max-concurrency= 10
#一个消费者最多可处理的nack消息数量，如果有事务的话，必须大于等于transaction数量
spring.rabbitmq.listener.simple.prefetch= 1
#是否启动时自动启动容器
spring.rabbitmq.listener.simple.auto-startup=true
#决定被拒绝的消息是否重新入队；默认是true（与参数acknowledge-mode有关系）
spring.rabbitmq.listener.simple.default-requeue-rejected= true
#发送重试是否可用
spring.rabbitmq.template.retry.enabled=true 
#第一次和第二次尝试发布或传递消息之间的间隔
spring.rabbitmq.template.retry.initial-interval=1000 
#最大重试次数
spring.rabbitmq.template.retry.max-attempts=3
#最大重试时间间隔
spring.rabbitmq.template.retry.max-interval=10000
#应用于上一重试间隔的乘数
spring.rabbitmq.template.retry.multiplier=1.0


#rocketmq 相关配置（rockmqtemplate 无法和artifactId：rocketmq-client一同配置，否则启动时报错producer.start()已经启动） (artifactId：rocketmq-spring-boot-starter)
##服务端地址
#rocketmq.name-server=localhost:9876
##消息生产者组
#rocketmq.producer.group=trac_producer_group
##生产者主题
#rocketmq.producer.topic=transaction_topic
##tag1
#rocketmq.tag.apk=apk
##tag2
#rocketmq.tag.archive=archive
## 消息体的最大允许大小。。默认为 4 * 1024 * 1024B
#rocketmq.producer.max-message-size=4194304
## 同步发送消息时，失败重试次数。默认为 2 次。
#rocketmq.producer.retry-times-when-send-failed=2
## 异步发送消息时，失败重试次数。默认为 2 次
#rocketmq.producer.retry-times-when-send-async-failed=2
##发送消息超时时间，单位：毫秒。默认为 3000
#rocketmq.producer.send-message-timeout=3000
##密钥配置
#rocketmq.producer.access-key=
#rocketmq.producer.secret-key=
#rocketmq.consumer.access-key=
#rocketmq.consumer.secret-key=


# rocketmq 相关配置 (artifactId：rocketmq-client )
###producer
#该应用是否启用生产者
#rocketmq.producer.isOnOff=on
##发送同一类消息的设置为同一个group，保证唯一,默认不需要设置，rocketmq会使用ip@pid(pid代表jvm名字)作为唯一标示
#rocketmq.producer.groupName=${spring.application.name}
##mq的nameserver地址
#rocketmq.producer.namesrvAddr=localhost:9876
##消息最大长度 默认1024*4(4M)
#rocketmq.producer.maxMessageSize=4096
##发送消息超时时间,默认3000
#rocketmq.producer.sendMsgTimeout=3000
##发送消息失败重试次数，默认2
#rocketmq.producer.retryTimesWhenSendFailed=2
#
####consumer
###该应用是否启用消费者
#rocketmq.consumer.isOnOff=on
#rocketmq.consumer.groupName=${spring.application.name}
##mq的nameserver地址
#rocketmq.consumer.namesrvAddr=localhost:9876
##该消费者订阅的主题和tags("*"号表示订阅该主题下所有的tags),格式：topic~tag1||tag2||tag3;topic2~*;
##rocketmq.consumer.topics=DemoTopic~*;
#rocketmq.consumer.topics=DemoTopic;
#rocketmq.consumer.consumeThreadMin=20
#rocketmq.consumer.consumeThreadMax=64
##设置一次消费消息的条数，默认为1条
#rocketmq.consumer.consumeMessageBatchMaxSize=1


#kafka相关配置

#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=localhost:9092
#=============== provider  =======================
spring.kafka.producer.servers=localhost:9092
kafka.producer.servers=localhost:9092
spring.kafka.producer.topic=product
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432


# producer组将会汇总任何在请求与发送之间到达的消息记录一个单独批量的请求。通常来说，这只有在记录产生速度大于发送速度的时候才能发生。然而，在某些条件下，客户端将希望降低请求的数量，甚至降低到中等负载一下。这项设置将通过增加小的延迟来完成–即，不是立即发送一条记录，producer将会等待给定的延迟时间以允许其他消息记录发送，这些消息记录可以批量处理。这可以认为是TCP种Nagle的算法类似。这项设置设定了批量处理的更高的延迟边界：一旦我们获得某个partition的batch.size，他将会立即发送而不顾这项设置，然而如果我们获得消息字节数比这项设置要小的多，我们需要“linger”特定的时间以获取更多的消息。 这个设置默认为0，即没有延迟。设定linger.ms=5，例如，将会减少请求数目，但是同时会增加5ms的延迟。
spring.kafka.producer.properties.linger=0


# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-demo-group
kafka.consumer.topic=product
spring.kafka.consumer.servers=localhost:9092
#org.apache.kafka.clients.consumer.KafkaConsumer 默认使用 kafka.consumer.servers 配置而不是 上面spring.kafka.consumer.servers这个配置
kafka.consumer.servers=localhost:9092
kafka.consumer.session.timeout=20000
spring.kafka.consumer.concurrency=10
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer


#sharding jdbc
#定义分片规则
#配置数据分片
spring.shardingsphere.datasource.names=m1

spring.shardingsphere.datasource.m1.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.m1.driver-class-name=com.mysql.jdbc.Driver
spring.shardingsphere.datasource.m1.url=jdbc:mysql://localhost:3306/seckill?useUnicode=true&characterEncoding=utf-8
spring.shardingsphere.datasource.m1.username=root
spring.shardingsphere.datasource.m1.password=yuantu123
#指定t_order表的配置主键生成策略SNOWFLAKE 即雪花算法
spring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id
spring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKE
#指定t_order表的数据分布状况，配置数据节点
spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=m1.t_order_$->{1..2}
#指定t_order表的分片策略，包括分片键和分片算法
spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=order_id
spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$->{order_id % 2 + 1}
#打开sharding jdbc sql输出日志
spring.shardingsphere.props.sql.show=true







